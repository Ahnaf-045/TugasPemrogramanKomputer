{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWPRjQVmV+McyVLPnKF6Vj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahnaf-045/TugasPemrogramanKomputer/blob/main/Tugas_Minggu_12_Kelompok_10_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwo5aDZGMvU4",
        "outputId": "b6443858-86a1-479f-faee-d615250f1545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.0)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio geopandas gdown pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.sample import sample_gen\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "def download_and_process_data():\n",
        "    \"\"\"\n",
        "    Process geospatial data from GeoTIFF, GPKG, and CSV files.\n",
        "\n",
        "    Note: Download the files from Google Drive first:\n",
        "    1. GeoTIFF: https://drive.google.com/file/d/1-Zdq_ZXj4WoX5ubQnoHRjSlHfHrx07x0/view?usp=sharing\n",
        "    2. GPKG: https://drive.google.com/file/d/1AQcHlqzmpQIukLyPIkUnb04-pbjoET_y/view?usp=sharing\n",
        "    3. CSV: https://drive.google.com/file/d/1v8_2PwMxl1QGdcbC_RPgUGtYSZsmJDri/view?usp=sharing\n",
        "    \"\"\"\n",
        "\n",
        "    # File paths (update these to match your downloaded files)\n",
        "    geotiff_path = \"your_geotiff_file.tif\"  # Replace with actual filename\n",
        "    gpkg_path = \"your_survey_data.gpkg\"     # Replace with actual filename\n",
        "    csv_path = \"perioda.csv\"                # Replace with actual filename\n",
        "\n",
        "    print(\"Starting geospatial data processing...\")\n",
        "\n",
        "    # Step 1: Load survey data from GPKG\n",
        "    print(\"Loading survey data from GPKG...\")\n",
        "    try:\n",
        "        survey_data = gpd.read_file(gpkg_path)\n",
        "        print(f\"Survey data loaded: {len(survey_data)} records\")\n",
        "        print(\"Columns:\", survey_data.columns.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading GPKG: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Load period lookup table\n",
        "    print(\"Loading period lookup table...\")\n",
        "    try:\n",
        "        period_lookup = pd.read_csv(csv_path)\n",
        "        print(f\"Period lookup loaded: {len(period_lookup)} records\")\n",
        "        print(\"Columns:\", period_lookup.columns.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: Filter and prepare survey data\n",
        "    print(\"Filtering survey data...\")\n",
        "\n",
        "    # Extract coordinates (assuming geometry column exists)\n",
        "    if 'geometry' in survey_data.columns:\n",
        "        survey_data['lon'] = survey_data.geometry.x\n",
        "        survey_data['lat'] = survey_data.geometry.y\n",
        "\n",
        "    # Create filtered table with required columns\n",
        "    # Adjust column names based on your actual data structure\n",
        "    required_cols = ['fid', 'lon', 'lat', 'date', 'fase']\n",
        "\n",
        "    # Check which columns exist and map them\n",
        "    available_cols = survey_data.columns.tolist()\n",
        "    print(f\"Available columns: {available_cols}\")\n",
        "\n",
        "    # Create mapping for common column name variations\n",
        "    column_mapping = {}\n",
        "    for col in required_cols:\n",
        "        if col in available_cols:\n",
        "            column_mapping[col] = col\n",
        "        elif col.upper() in available_cols:\n",
        "            column_mapping[col] = col.upper()\n",
        "        elif col.lower() in available_cols:\n",
        "            column_mapping[col] = col.lower()\n",
        "        elif col == 'fid' and 'FID' in available_cols:\n",
        "            column_mapping[col] = 'FID'\n",
        "        elif col == 'fid' and 'id' in available_cols:\n",
        "            column_mapping[col] = 'id'\n",
        "        elif col == 'date' and 'Date' in available_cols:\n",
        "            column_mapping[col] = 'Date'\n",
        "        elif col == 'fase' and 'phase' in available_cols:\n",
        "            column_mapping[col] = 'phase'\n",
        "\n",
        "    # Filter data with existing columns\n",
        "    filtered_data = survey_data.copy()\n",
        "\n",
        "    # Rename columns to standard names\n",
        "    for new_name, old_name in column_mapping.items():\n",
        "        if old_name in filtered_data.columns:\n",
        "            filtered_data = filtered_data.rename(columns={old_name: new_name})\n",
        "\n",
        "    # Select only required columns that exist\n",
        "    existing_cols = [col for col in required_cols if col in filtered_data.columns]\n",
        "    filtered_survey = filtered_data[existing_cols + ['geometry'] if 'geometry' in filtered_data.columns else existing_cols].copy()\n",
        "\n",
        "    print(f\"Filtered survey data: {len(filtered_survey)} records\")\n",
        "    print(\"Table 1 - Filtered Survey Data:\")\n",
        "    print(filtered_survey.head())\n",
        "\n",
        "    # Step 4: Add period information\n",
        "    print(\"Adding period information...\")\n",
        "\n",
        "    # Merge with period lookup table\n",
        "    # Adjust merge column based on your data structure\n",
        "    if 'date' in filtered_survey.columns and len(period_lookup.columns) >= 2:\n",
        "        # Assuming period lookup has date and period columns\n",
        "        period_col_names = period_lookup.columns.tolist()\n",
        "\n",
        "        # Convert date columns to datetime for proper matching\n",
        "        if 'date' in filtered_survey.columns:\n",
        "            try:\n",
        "                filtered_survey['date'] = pd.to_datetime(filtered_survey['date'])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Merge based on the first column of period lookup (assuming it's the key)\n",
        "        merge_key = period_col_names[0]\n",
        "        period_key = period_col_names[1] if len(period_col_names) > 1 else 'periode'\n",
        "\n",
        "        try:\n",
        "            # Try different merge strategies\n",
        "            if merge_key in filtered_survey.columns:\n",
        "                survey_with_period = filtered_survey.merge(\n",
        "                    period_lookup,\n",
        "                    left_on=merge_key,\n",
        "                    right_on=period_col_names[0],\n",
        "                    how='left'\n",
        "                )\n",
        "            else:\n",
        "                # Create a simple period assignment based on date ranges or other logic\n",
        "                survey_with_period = filtered_survey.copy()\n",
        "                survey_with_period['periode'] = 1  # Default period\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Merge error: {e}\")\n",
        "            survey_with_period = filtered_survey.copy()\n",
        "            survey_with_period['periode'] = 1  # Default period\n",
        "    else:\n",
        "        survey_with_period = filtered_survey.copy()\n",
        "        survey_with_period['periode'] = 1  # Default period\n",
        "\n",
        "    print(\"Table 2 - Survey Data with Period:\")\n",
        "    print(survey_with_period.head())\n",
        "\n",
        "    # Step 5: Extract raster values\n",
        "    print(\"Extracting raster values...\")\n",
        "\n",
        "    try:\n",
        "        with rasterio.open(geotiff_path) as src:\n",
        "            print(f\"Raster info: {src.count} bands, {src.width}x{src.height} pixels\")\n",
        "\n",
        "            # Prepare coordinates for sampling\n",
        "            coords = [(lon, lat) for lon, lat in zip(survey_with_period['lon'], survey_with_period['lat'])]\n",
        "\n",
        "            # Extract values for each point and each period\n",
        "            final_results = []\n",
        "\n",
        "            for idx, row in survey_with_period.iterrows():\n",
        "                try:\n",
        "                    coord = (row['lon'], row['lat'])\n",
        "                    periode = int(row.get('periode', 1))\n",
        "\n",
        "                    # Ensure period is within valid band range\n",
        "                    if periode > src.count:\n",
        "                        periode = 1\n",
        "\n",
        "                    # Sample the raster at the point location for the specific band\n",
        "                    sampled_values = list(sample_gen(src, [coord], indexes=[periode]))\n",
        "                    p0_value = sampled_values[0][0] if sampled_values and len(sampled_values[0]) > 0 else np.nan\n",
        "\n",
        "                    # Create result row\n",
        "                    result_row = {\n",
        "                        'fid': row.get('fid', idx),\n",
        "                        'lon': row['lon'],\n",
        "                        'lat': row['lat'],\n",
        "                        'date': row.get('date', ''),\n",
        "                        'fase': row.get('fase', ''),\n",
        "                        'periode': periode,\n",
        "                        'p0': p0_value\n",
        "                    }\n",
        "\n",
        "                    final_results.append(result_row)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing point {idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Create final DataFrame\n",
        "            final_df = pd.DataFrame(final_results)\n",
        "\n",
        "            print(\"Table 3 - Final Results with Raster Values:\")\n",
        "            print(final_df.head())\n",
        "            print(f\"\\nFinal dataset: {len(final_df)} records\")\n",
        "\n",
        "            # Save results\n",
        "            output_file = \"processed_survey_data.csv\"\n",
        "            final_df.to_csv(output_file, index=False)\n",
        "            print(f\"Results saved to: {output_file}\")\n",
        "\n",
        "            return final_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing raster: {e}\")\n",
        "        return survey_with_period\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the data processing pipeline.\n",
        "    \"\"\"\n",
        "    print(\"=== Geospatial Data Processing Pipeline ===\")\n",
        "    print()\n",
        "    print(\"Before running this script, please:\")\n",
        "    print(\"1. Download the GeoTIFF file from Google Drive\")\n",
        "    print(\"2. Download the GPKG survey data file from Google Drive\")\n",
        "    print(\"3. Download the perioda.csv file from Google Drive\")\n",
        "    print(\"4. Update the file paths in the script\")\n",
        "    print()\n",
        "\n",
        "    # Check if files exist\n",
        "    files_to_check = [\"your_geotiff_file.tif\", \"your_survey_data.gpkg\", \"perioda.csv\"]\n",
        "    missing_files = [f for f in files_to_check if not os.path.exists(f)]\n",
        "\n",
        "    if missing_files:\n",
        "        print(\"Missing files:\")\n",
        "        for f in missing_files:\n",
        "            print(f\"  - {f}\")\n",
        "        print(\"\\nPlease download and update file paths before running.\")\n",
        "        return\n",
        "\n",
        "    # Process the data\n",
        "    result = download_and_process_data()\n",
        "\n",
        "    if result is not None:\n",
        "        print(\"\\n=== Processing Complete ===\")\n",
        "        print(\"Three tables have been generated:\")\n",
        "        print(\"1. Filtered survey data (fid, lon, lat, date, fase)\")\n",
        "        print(\"2. Survey data with period (fid, lon, lat, date, fase, periode)\")\n",
        "        print(\"3. Final data with raster values (fid, lon, lat, date, fase, periode, p0)\")\n",
        "    else:\n",
        "        print(\"Processing failed. Please check file paths and data format.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "# Alternative function for manual file processing\n",
        "def process_with_custom_paths(geotiff_path, gpkg_path, csv_path):\n",
        "    \"\"\"\n",
        "    Process data with custom file paths.\n",
        "\n",
        "    Args:\n",
        "        geotiff_path (str): Path to GeoTIFF file\n",
        "        gpkg_path (str): Path to GPKG file\n",
        "        csv_path (str): Path to CSV file\n",
        "    \"\"\"\n",
        "    # Update the file paths in the global scope\n",
        "    globals()['geotiff_path'] = geotiff_path\n",
        "    globals()['gpkg_path'] = gpkg_path\n",
        "    globals()['csv_path'] = csv_path\n",
        "\n",
        "    return download_and_process_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NHprCAOP2wQ",
        "outputId": "9622c51c-197d-47f9-bdc1-713d3f728348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Geospatial Data Processing Pipeline ===\n",
            "\n",
            "Before running this script, please:\n",
            "1. Download the GeoTIFF file from Google Drive\n",
            "2. Download the GPKG survey data file from Google Drive\n",
            "3. Download the perioda.csv file from Google Drive\n",
            "4. Update the file paths in the script\n",
            "\n",
            "Missing files:\n",
            "  - your_geotiff_file.tif\n",
            "  - your_survey_data.gpkg\n",
            "  - perioda.csv\n",
            "\n",
            "Please download and update file paths before running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import gdown\n",
        "    import pandas as pd\n",
        "    import geopandas as gpd\n",
        "    import rasterio\n",
        "    from rasterio.sample import sample_gen\n",
        "    import numpy as np\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "except ImportError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please install missing packages using:\")\n",
        "    print(\"!pip install rasterio geopandas gdown pandas numpy\")\n",
        "    raise\n",
        "\n",
        "# Rest of your code...\n",
        "def download_and_process_data():\n",
        "    \"\"\"\n",
        "    Download and process geospatial data from Google Drive links.\n",
        "    \"\"\"\n",
        "    # Google Drive URLs and output files\n",
        "    geotiff_url = \"https://drive.google.com/uc?id=1-Zdq_ZXj4WoX5ubQnoHRjSlHfHrx07x0\"\n",
        "    gpkg_url = \"https://drive.google.com/uc?id=1AQcHlqzmpQIukLyPIkUnb04-pbjoET_y\"\n",
        "    csv_url = \"https://drive.google.com/uc?id=1v8_2PwMxl1QGdcbC_RPgUGtYSZsmJDri\"\n",
        "\n",
        "    geotiff_path = \"downloaded_geotiff.tif\"\n",
        "    gpkg_path = \"downloaded_survey.gpkg\"\n",
        "    csv_path = \"perioda.csv\"\n",
        "\n",
        "    print(\"Starting download and processing...\")\n",
        "\n",
        "    # Download files using gdown\n",
        "    try:\n",
        "        print(\"Downloading GeoTIFF...\")\n",
        "        gdown.download(geotiff_url, geotiff_path, quiet=False)\n",
        "\n",
        "        print(\"Downloading GPKG...\")\n",
        "        gdown.download(gpkg_url, gpkg_path, quiet=False)\n",
        "\n",
        "        print(\"Downloading CSV...\")\n",
        "        gdown.download(csv_url, csv_path, quiet=False)\n",
        "\n",
        "        print(\"All files downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Download error: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 1: Load and prepare survey data\n",
        "    print(\"\\nLoading survey data from GPKG...\")\n",
        "    try:\n",
        "        survey_data = gpd.read_file(gpkg_path).to_crs(epsg=4326)\n",
        "        survey_data[\"lon\"] = survey_data.geometry.x\n",
        "        survey_data[\"lat\"] = survey_data.geometry.y\n",
        "        survey_data[\"fid\"] = survey_data.index.astype(int)\n",
        "\n",
        "        # Handle column name variations\n",
        "        if \"tanggal\" in survey_data.columns:\n",
        "            survey_data = survey_data.rename(columns={\"tanggal\": \"date\"})\n",
        "        if \"Phase\" in survey_data.columns:\n",
        "            survey_data = survey_data.rename(columns={\"Phase\": \"fase\"})\n",
        "\n",
        "        # Select required columns\n",
        "        required_cols = ['fid', 'lon', 'lat', 'date', 'fase']\n",
        "        missing_cols = [c for c in required_cols if c not in survey_data.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "            print(f\"Warning: Missing columns: {missing_cols}. Adding with default values.\")\n",
        "            for col in missing_cols:\n",
        "                if col == 'date':\n",
        "                    survey_data[col] = datetime.now().strftime('%Y-%m-%d')\n",
        "                elif col == 'fase':\n",
        "                    survey_data[col] = 'unknown'\n",
        "\n",
        "        output1 = survey_data[required_cols].copy()\n",
        "        print(\"\\n✅ TABEL 1 - Filtered survey data\")\n",
        "        print(output1.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading GPKG: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Load and merge period data\n",
        "    print(\"\\nLoading period lookup table...\")\n",
        "    try:\n",
        "        period_lookup = pd.read_csv(csv_path, sep=';')\n",
        "        period_lookup = period_lookup.rename(columns={\"Periode\": \"fase\"})\n",
        "        period_lookup['fase'] = period_lookup['fase'].astype(str).str.strip()\n",
        "        output1['fase'] = output1['fase'].astype(str).str.strip()\n",
        "\n",
        "        output2 = pd.merge(output1, period_lookup, on=\"fase\", how=\"left\")\n",
        "\n",
        "        # Convert fase to integer for band selection\n",
        "        try:\n",
        "            output2[\"periode\"] = output2[\"fase\"].astype(int)\n",
        "        except ValueError:\n",
        "            print(\"Warning: Could not convert 'fase' to integer. Using default period 1.\")\n",
        "            output2[\"periode\"] = 1\n",
        "\n",
        "        print(\"\\n✅ TABEL 2 - Survey data with period\")\n",
        "        print(output2.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading/merging CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: Extract raster values\n",
        "    print(\"\\nExtracting raster values...\")\n",
        "    try:\n",
        "        with rasterio.open(geotiff_path) as src:\n",
        "            print(f\"Raster info: {src.count} bands, {src.width}x{src.height} pixels\")\n",
        "\n",
        "            def get_pixel_value(lon, lat, band):\n",
        "                try:\n",
        "                    if not 1 <= band <= src.count:\n",
        "                        return None\n",
        "                    for val in sample_gen(src, [(lon, lat)], indexes=[band]):\n",
        "                        return val[0]\n",
        "                except Exception as e:\n",
        "                    print(f\"Error at ({lon}, {lat}) band {band}: {e}\")\n",
        "                    return None\n",
        "\n",
        "            output2[\"p0\"] = output2.apply(\n",
        "                lambda row: get_pixel_value(row[\"lon\"], row[\"lat\"], row[\"periode\"]),\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "            output3 = output2[['fid', 'lon', 'lat', 'date', 'fase', 'periode', 'p0']]\n",
        "            print(\"\\n✅ TABEL 3 - Final results with raster values\")\n",
        "            print(output3.head())\n",
        "\n",
        "            # Save results\n",
        "            output_file = \"processed_survey_data.csv\"\n",
        "            output3.to_csv(output_file, index=False)\n",
        "            print(f\"\\nResults saved to: {output_file}\")\n",
        "\n",
        "            # Clean up\n",
        "            for file in [geotiff_path, gpkg_path, csv_path]:\n",
        "                try:\n",
        "                    if os.path.exists(file):\n",
        "                        os.remove(file)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            return output3\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing raster: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"=== Geospatial Data Processing Pipeline ===\")\n",
        "    result = download_and_process_data()\n",
        "\n",
        "    if result is not None:\n",
        "        print(\"\\n=== Processing Complete ===\")\n",
        "        print(\"Tiga tabel telah berhasil dibuat:\")\n",
        "        print(\"1. TABEL 1: Data survey terfilter\")\n",
        "        print(\"2. TABEL 2: Data survey dengan periode\")\n",
        "        print(\"3. TABEL 3: Data final dengan nilai raster\")\n",
        "    else:\n",
        "        print(\"Processing failed. Please check the error messages.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY-BQNij1oUP",
        "outputId": "7c7f3350-7fec-4389-fa57-5aad779a98ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Geospatial Data Processing Pipeline ===\n",
            "Starting download and processing...\n",
            "Downloading GeoTIFF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-Zdq_ZXj4WoX5ubQnoHRjSlHfHrx07x0\n",
            "From (redirected): https://drive.google.com/uc?id=1-Zdq_ZXj4WoX5ubQnoHRjSlHfHrx07x0&confirm=t&uuid=c03743cb-dcc8-4625-b948-75ce51b19698\n",
            "To: /content/downloaded_geotiff.tif\n",
            "100%|██████████| 1.92G/1.92G [00:11<00:00, 166MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GPKG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AQcHlqzmpQIukLyPIkUnb04-pbjoET_y\n",
            "To: /content/downloaded_survey.gpkg\n",
            "100%|██████████| 1.62M/1.62M [00:00<00:00, 117MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CSV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v8_2PwMxl1QGdcbC_RPgUGtYSZsmJDri\n",
            "To: /content/perioda.csv\n",
            "100%|██████████| 827/827 [00:00<00:00, 1.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files downloaded successfully!\n",
            "\n",
            "Loading survey data from GPKG...\n",
            "\n",
            "✅ TABEL 1 - Filtered survey data\n",
            "   fid         lon       lat       date  fase\n",
            "0    0  107.463959 -6.260439  3/18/2024     1\n",
            "1    1  107.464081 -6.260284  3/18/2024     1\n",
            "2    2  107.463608 -6.260762  3/18/2024     1\n",
            "3    3  107.461742 -6.261511  3/18/2024     1\n",
            "4    4  107.463209 -6.260423  3/18/2024     1\n",
            "\n",
            "Loading period lookup table...\n",
            "\n",
            "✅ TABEL 2 - Survey data with period\n",
            "   fid         lon       lat       date fase  Start Date    End Date  periode\n",
            "0    0  107.463959 -6.260439  3/18/2024    1  2024-01-01  2024-01-13        1\n",
            "1    1  107.464081 -6.260284  3/18/2024    1  2024-01-01  2024-01-13        1\n",
            "2    2  107.463608 -6.260762  3/18/2024    1  2024-01-01  2024-01-13        1\n",
            "3    3  107.461742 -6.261511  3/18/2024    1  2024-01-01  2024-01-13        1\n",
            "4    4  107.463209 -6.260423  3/18/2024    1  2024-01-01  2024-01-13        1\n",
            "\n",
            "Extracting raster values...\n",
            "Raster info: 31 bands, 8079x3834 pixels\n",
            "\n",
            "✅ TABEL 3 - Final results with raster values\n",
            "   fid         lon       lat       date fase  periode    p0\n",
            "0    0  107.463959 -6.260439  3/18/2024    1        1 -1379\n",
            "1    1  107.464081 -6.260284  3/18/2024    1        1 -1410\n",
            "2    2  107.463608 -6.260762  3/18/2024    1        1 -1420\n",
            "3    3  107.461742 -6.261511  3/18/2024    1        1 -1524\n",
            "4    4  107.463209 -6.260423  3/18/2024    1        1 -1418\n",
            "\n",
            "Results saved to: processed_survey_data.csv\n",
            "\n",
            "=== Processing Complete ===\n",
            "Tiga tabel telah berhasil dibuat:\n",
            "1. TABEL 1: Data survey terfilter\n",
            "2. TABEL 2: Data survey dengan periode\n",
            "3. TABEL 3: Data final dengan nilai raster\n"
          ]
        }
      ]
    }
  ]
}